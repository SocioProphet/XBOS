{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "_Rendezvous",
     "evalue": "<_Rendezvous of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"did not fetch data from pymortar with query: SELECT ?temp WHERE {\n        ?temp rdf:type brick:Weather_Temperature_Sensor .\n    };\"\n\tdebug_error_string = \"{\"created\":\"@1558133261.520962000\",\"description\":\"Error received from peer\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1017,\"grpc_message\":\"did not fetch data from pymortar with query: SELECT ?temp WHERE {\\n        ?temp rdf:type brick:Weather_Temperature_Sensor .\\n    };\",\"grpc_status\":3}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_Rendezvous\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-6d18991d0889>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mtemperature_band_stub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxbos_services_getter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_temperature_band_stub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ms.xbos.io:9001\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0moutdoor_temp_stub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxbos_services_getter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_outdoor_temperature_historic_stub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ms.xbos.io:9001\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0moutdoor_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxbos_services_getter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_outdoor_temperature_historic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdoor_temp_stub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"orinda-community-center\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m# consumption_stub = xbos_services_getter.get_consumption_historic_stub()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mhvac_consumption_stub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxbos_services_getter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hvac_consumption_stub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ms.xbos.io:9001\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xbos_services_getter/xbos_services_getter.py\u001b[0m in \u001b[0;36mget_outdoor_temperature_historic\u001b[0;34m(outdoor_historic_stub, building, start, end, window)\u001b[0m\n\u001b[1;32m    696\u001b[0m     historic_outdoor_response = outdoor_historic_stub.GetTemperature(\n\u001b[1;32m    697\u001b[0m         outdoor_temperature_historical_pb2.TemperatureRequest(\n\u001b[0;32m--> 698\u001b[0;31m             building=building, start=int(start_unix), end=int(end_unix), window=window))\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;31m# process data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwith_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_Rendezvous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_Rendezvous\u001b[0m: <_Rendezvous of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"did not fetch data from pymortar with query: SELECT ?temp WHERE {\n        ?temp rdf:type brick:Weather_Temperature_Sensor .\n    };\"\n\tdebug_error_string = \"{\"created\":\"@1558133261.520962000\",\"description\":\"Error received from peer\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1017,\"grpc_message\":\"did not fetch data from pymortar with query: SELECT ?temp WHERE {\\n        ?temp rdf:type brick:Weather_Temperature_Sensor .\\n    };\",\"grpc_status\":3}\"\n>"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "import xbos_services_getter\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "from scipy import spatial\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "start = datetime.datetime(year=2017, month=12, day=31, hour=16, minute=0).replace(tzinfo=pytz.utc)\n",
    "end = datetime.datetime(year = 2018, month = 5, day = 18, hour = 23, minute = 45).replace(tzinfo=pytz.utc)\n",
    "\n",
    "window = \"15m\"\n",
    "aggregate = 'MEAN'\n",
    "\n",
    "building_stub = xbos_services_getter.xbos_services_getter.get_building_zone_names_stub(\"ms.xbos.io:9001\", secure=True)\n",
    "\n",
    "\n",
    "buildings = xbos_services_getter.xbos_services_getter.get_buildings(building_stub)\n",
    "building_zone_names_stub = xbos_services_getter.get_building_zone_names_stub(\"ms.xbos.io:9001\")\n",
    "\n",
    "zones = xbos_services_getter.get_zones(building_stub, \"orinda-community-center\")\n",
    "\n",
    "temperature_band_stub = xbos_services_getter.get_temperature_band_stub(\"ms.xbos.io:9001\",secure=True)\n",
    "outdoor_temp_stub = xbos_services_getter.get_outdoor_temperature_historic_stub(\"ms.xbos.io:9001\",secure=True)\n",
    "outdoor_temp = xbos_services_getter.get_outdoor_temperature_historic(outdoor_temp_stub, \"orinda-community-center\", start, end,  window) \n",
    "# consumption_stub = xbos_services_getter.get_consumption_historic_stub()\n",
    "hvac_consumption_stub = xbos_services_getter.get_hvac_consumption_stub(\"ms.xbos.io:9001\",secure=True)\n",
    "hvac_consumption = xbos_services_getter.get_hvac_consumption(hvac_consumption_stub, \"orinda-community-center\", zone = 'hvac_zone_ac_7')\n",
    "indoor_data_historical_stub = xbos_services_getter.get_indoor_historic_stub(\"ms.xbos.io:9001\", secure=True)\n",
    "meter_data_historical_stub = xbos_services_getter.get_meter_data_historical_stub(\"ms.xbos.io:9001\", secure = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hvac_zone_ac_7',\n",
       " 'hvac_zone_rm7',\n",
       " 'hvac_zone_kinder_gym',\n",
       " 'hvac_zone_ac_6',\n",
       " 'hvac_zone_ac_3',\n",
       " 'hvac_zone_rm1',\n",
       " 'hvac_zone_ac_4',\n",
       " 'hvac_zone_ac_5',\n",
       " 'hvac_zone_rm6',\n",
       " 'hvac_zone_ac_1',\n",
       " 'hvac_zone_front_office',\n",
       " 'hvac_zone_ac_2',\n",
       " 'hvac_zone_rm2',\n",
       " 'hvac_zone_ac_8']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 0.075, 2: 3.3, 3: 0.01, 4: nan, 5: nan, 'UNIT': 'kWh'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvac_consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bldg = \"avenal-recreation-center\"\n",
    "\n",
    "electric_meter_data = xbos_services_getter.get_meter_data_historical(meter_data_historical_stub,bldg,start,end,electric_point_type,aggregate,window)\n",
    "\n",
    "zones = xbos_services_getter.get_zones(building_zone_names_stub,bldg)\n",
    "\n",
    "data = pd.concat([action_df, electric_meter_data], axis =1)\n",
    "data[\"X\"] = data.index\n",
    "\n",
    "data.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 15, 'min_impurity_decrease': 1e-08, 'min_samples_leaf': 3, 'min_samples_split': 15, 'n_estimators': 125}\n",
      "avenal-recreation-center is empty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 48.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'min_impurity_decrease': 1e-06, 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_impurity_decrease': 1e-08, 'min_samples_leaf': 7, 'min_samples_split': 15, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 18.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_impurity_decrease': 1e-07, 'min_samples_leaf': 20, 'min_samples_split': 20, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 29.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_impurity_decrease': 1e-06, 'min_samples_leaf': 7, 'min_samples_split': 25, 'n_estimators': 50}\n",
      "                           power\n",
      "datetime                        \n",
      "2017-12-31 16:00:00+00:00    NaN\n",
      "2017-12-31 16:15:00+00:00    NaN\n",
      "2017-12-31 16:30:00+00:00    NaN\n",
      "2017-12-31 16:45:00+00:00    NaN\n",
      "2017-12-31 17:00:00+00:00    NaN\n",
      "2017-12-31 17:15:00+00:00    NaN\n",
      "2017-12-31 17:30:00+00:00    NaN\n",
      "2017-12-31 17:45:00+00:00    NaN\n",
      "2017-12-31 18:00:00+00:00    NaN\n",
      "2017-12-31 18:15:00+00:00    NaN\n",
      "2017-12-31 18:30:00+00:00    NaN\n",
      "2017-12-31 18:45:00+00:00    NaN\n",
      "2017-12-31 19:00:00+00:00    NaN\n",
      "2017-12-31 19:15:00+00:00    NaN\n",
      "2017-12-31 19:30:00+00:00    NaN\n",
      "2017-12-31 19:45:00+00:00    NaN\n",
      "2017-12-31 20:00:00+00:00    NaN\n",
      "2017-12-31 20:15:00+00:00    NaN\n",
      "2017-12-31 20:30:00+00:00    NaN\n",
      "2017-12-31 20:45:00+00:00    NaN\n",
      "2017-12-31 21:00:00+00:00    NaN\n",
      "2017-12-31 21:15:00+00:00    NaN\n",
      "2017-12-31 21:30:00+00:00    NaN\n",
      "2017-12-31 21:45:00+00:00    NaN\n",
      "2017-12-31 22:00:00+00:00    NaN\n",
      "2017-12-31 22:15:00+00:00    NaN\n",
      "2017-12-31 22:30:00+00:00    NaN\n",
      "2017-12-31 22:45:00+00:00    NaN\n",
      "2017-12-31 23:00:00+00:00    NaN\n",
      "2017-12-31 23:15:00+00:00    NaN\n",
      "...                          ...\n",
      "2018-05-18 16:00:00+00:00    NaN\n",
      "2018-05-18 16:15:00+00:00    NaN\n",
      "2018-05-18 16:30:00+00:00    NaN\n",
      "2018-05-18 16:45:00+00:00    NaN\n",
      "2018-05-18 17:00:00+00:00    NaN\n",
      "2018-05-18 17:15:00+00:00    NaN\n",
      "2018-05-18 17:30:00+00:00    NaN\n",
      "2018-05-18 17:45:00+00:00    NaN\n",
      "2018-05-18 18:00:00+00:00    NaN\n",
      "2018-05-18 18:15:00+00:00    NaN\n",
      "2018-05-18 18:30:00+00:00    NaN\n",
      "2018-05-18 18:45:00+00:00    NaN\n",
      "2018-05-18 19:00:00+00:00    NaN\n",
      "2018-05-18 19:15:00+00:00    NaN\n",
      "2018-05-18 19:30:00+00:00    NaN\n",
      "2018-05-18 19:45:00+00:00    NaN\n",
      "2018-05-18 20:00:00+00:00    NaN\n",
      "2018-05-18 20:15:00+00:00    NaN\n",
      "2018-05-18 20:30:00+00:00    NaN\n",
      "2018-05-18 20:45:00+00:00    NaN\n",
      "2018-05-18 21:00:00+00:00    NaN\n",
      "2018-05-18 21:15:00+00:00    NaN\n",
      "2018-05-18 21:30:00+00:00    NaN\n",
      "2018-05-18 21:45:00+00:00    NaN\n",
      "2018-05-18 22:00:00+00:00    NaN\n",
      "2018-05-18 22:15:00+00:00    NaN\n",
      "2018-05-18 22:30:00+00:00    NaN\n",
      "2018-05-18 22:45:00+00:00    NaN\n",
      "2018-05-18 23:00:00+00:00    NaN\n",
      "2018-05-18 23:15:00+00:00    NaN\n",
      "\n",
      "[13278 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 22.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_impurity_decrease': 1e-06, 'min_samples_leaf': 15, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "no meter or greenbutton data for csu-dominguez-hills\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed:  9.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_impurity_decrease': 1e-08, 'min_samples_leaf': 20, 'min_samples_split': 20, 'n_estimators': 125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 1146.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_impurity_decrease': 1e-07, 'min_samples_leaf': 15, 'min_samples_split': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 24.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_impurity_decrease': 1e-08, 'min_samples_leaf': 7, 'min_samples_split': 25, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_impurity_decrease': 1e-07, 'min_samples_leaf': 3, 'min_samples_split': 20, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 13.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_impurity_decrease': 1e-06, 'min_samples_leaf': 20, 'min_samples_split': 10, 'n_estimators': 75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 13.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_impurity_decrease': 1e-08, 'min_samples_leaf': 3, 'min_samples_split': 25, 'n_estimators': 75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n",
      "{'max_depth': 3, 'min_impurity_decrease': 1e-08, 'min_samples_leaf': 3, 'min_samples_split': 25, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed:  8.6min finished\n"
     ]
    }
   ],
   "source": [
    "electric_point_type = 'Building_Electric_Meter'\n",
    "\n",
    "best_params_dict = {}\n",
    "\n",
    "for bldg in buildings:\n",
    "    zones = xbos_services_getter.get_zones(building_zone_names_stub,bldg)\n",
    "    action_df=pd.DataFrame()\n",
    "    for zone in zones:\n",
    "        s = xbos_services_getter.get_indoor_actions_historic(indoor_data_historical_stub,bldg,zone,start,end,window,aggregate)\n",
    "        action_df = pd.concat([action_df, s], axis =1)\n",
    "\n",
    "    if bldg == \"csu-dominguez-hills\":\n",
    "        print(\"no meter or greenbutton data for csu-dominguez-hills\")\n",
    "        continue\n",
    "        \n",
    "# NO GREENBUTTON DATA FOR jesse-turner-center\n",
    "    if bldg == \"jesse-turner-center\":\n",
    "        electric_meter_data = xbos_services_getter.get_meter_data_historical(meter_data_historical_stub,bldg,start,end,electric_point_type,aggregate,window)\n",
    "\n",
    "    electric_meter_data = xbos_services_getter.get_meter_data_historical(meter_data_historical_stub,bldg,start,end,electric_point_type,aggregate,window)\n",
    "    \n",
    "    data = pd.concat([action_df, electric_meter_data], axis =1)\n",
    "    data[\"X\"] = data.index\n",
    "    data.rename(columns={\"power\":\"y\"}, inplace =True)\n",
    "    \n",
    "    scalerY = MinMaxScaler(feature_range=(0, 1))\n",
    "    scalerX = MinMaxScaler(feature_range=(0, 1))\n",
    "    scalerS = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    data[\"is_weekday\"] = [is_weekday(x.weekday()) for x in data[\"X\"]]\n",
    "    data[\"is_workday\"] = [is_workday(x.hour) for x in data[\"X\"]]\n",
    "    data[\"is_spring\"]= [is_Spring(x.month) for x in data[\"X\"]]\n",
    "    data[\"is_summer\"]= [is_Summer(x.month) for x in data[\"X\"]]\n",
    "    data[\"is_autumn\"]= [is_Autumn(x.month) for x in data[\"X\"]]\n",
    "    data[\"is_winter\"]= [is_Winter(x.month) for x in data[\"X\"]]\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    if data.empty:\n",
    "        print(bldg+\" is empty\")\n",
    "        continue\n",
    "    \n",
    "    data[\"X\"] = scalerX.fit_transform(data[\"X\"].values.reshape(-1,1))\n",
    "    data[\"y\"] = scalerY.fit_transform(data[\"y\"].values.reshape(-1,1))\n",
    "\n",
    "    prediction_window=16\n",
    "    training_data=data[:-prediction_window]\n",
    "    test_data = data[-prediction_window:]\n",
    "\n",
    "    train_labels = training_data[\"y\"]\n",
    "    train_features = training_data.drop(\"y\", axis = 1)\n",
    "    test_labels = test_data[\"y\"]\n",
    "    test_features = test_data.drop(\"y\", axis = 1)\n",
    "    \n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    parameters = {\n",
    "        'n_estimators':[50, 75,125],\n",
    "        'max_depth': [3, 5, 15,20],\n",
    "        \"min_samples_split\":[5,10, 15, 20, 25],\n",
    "        'min_samples_leaf': [3, 7, 12, 15, 20],\n",
    "        \"min_impurity_decrease\": [1e-7, 1e-6, 1e-8]\n",
    "    }\n",
    "\n",
    "    clf = GridSearchCV(rf, parameters, cv=3, verbose = 1)\n",
    "    clf.fit(train_features, train_labels)\n",
    "    \n",
    "    print(clf.best_params_)\n",
    "    best_params_dict[bldg] = clf.best_params_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avenal-veterans-hall': {'max_depth': 15,\n",
       "  'min_impurity_decrease': 1e-08,\n",
       "  'min_samples_leaf': 3,\n",
       "  'min_samples_split': 15,\n",
       "  'n_estimators': 125},\n",
       " 'orinda-community-center': {'max_depth': 20,\n",
       "  'min_impurity_decrease': 1e-06,\n",
       "  'min_samples_leaf': 3,\n",
       "  'min_samples_split': 5,\n",
       "  'n_estimators': 50},\n",
       " 'local-butcher-shop': {'max_depth': 3,\n",
       "  'min_impurity_decrease': 1e-08,\n",
       "  'min_samples_leaf': 7,\n",
       "  'min_samples_split': 15,\n",
       "  'n_estimators': 50},\n",
       " 'avenal-public-works-yard': {'max_depth': 3,\n",
       "  'min_impurity_decrease': 1e-07,\n",
       "  'min_samples_leaf': 20,\n",
       "  'min_samples_split': 20,\n",
       "  'n_estimators': 50},\n",
       " 'hayward-station-1': {'max_depth': 5,\n",
       "  'min_impurity_decrease': 1e-06,\n",
       "  'min_samples_leaf': 7,\n",
       "  'min_samples_split': 25,\n",
       "  'n_estimators': 50},\n",
       " 'ciee': {'max_depth': 5,\n",
       "  'min_impurity_decrease': 1e-06,\n",
       "  'min_samples_leaf': 15,\n",
       "  'min_samples_split': 5,\n",
       "  'n_estimators': 50},\n",
       " 'berkeley-corporate-yard': {'max_depth': 3,\n",
       "  'min_impurity_decrease': 1e-08,\n",
       "  'min_samples_leaf': 20,\n",
       "  'min_samples_split': 20,\n",
       "  'n_estimators': 125},\n",
       " 'south-berkeley-senior-center': {'max_depth': 5,\n",
       "  'min_impurity_decrease': 1e-07,\n",
       "  'min_samples_leaf': 15,\n",
       "  'min_samples_split': 10,\n",
       "  'n_estimators': 50},\n",
       " 'avenal-movie-theatre': {'max_depth': 5,\n",
       "  'min_impurity_decrease': 1e-08,\n",
       "  'min_samples_leaf': 7,\n",
       "  'min_samples_split': 25,\n",
       "  'n_estimators': 50},\n",
       " 'avenal-animal-shelter': {'max_depth': 3,\n",
       "  'min_impurity_decrease': 1e-07,\n",
       "  'min_samples_leaf': 3,\n",
       "  'min_samples_split': 20,\n",
       "  'n_estimators': 50},\n",
       " 'north-berkeley-senior-center': {'max_depth': 5,\n",
       "  'min_impurity_decrease': 1e-06,\n",
       "  'min_samples_leaf': 20,\n",
       "  'min_samples_split': 10,\n",
       "  'n_estimators': 75},\n",
       " 'word-of-faith-cc': {'max_depth': 5,\n",
       "  'min_impurity_decrease': 1e-08,\n",
       "  'min_samples_leaf': 3,\n",
       "  'min_samples_split': 25,\n",
       "  'n_estimators': 75},\n",
       " 'hayward-station-8': {'max_depth': 3,\n",
       "  'min_impurity_decrease': 1e-08,\n",
       "  'min_samples_leaf': 3,\n",
       "  'min_samples_split': 25,\n",
       "  'n_estimators': 50}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Evaluate model for predictions (quantitative)\n",
    "## prediction function \n",
    "# if time, make it autoregressive \n",
    "## lit review for HVAC consumption "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no meter or greenbutton data for csu-dominguez-hills\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "evaluate_metrics={}\n",
    "\n",
    "for bldg in buildings:\n",
    "    if bldg == \"avenal-recreation-center\":\n",
    "        # no data for this one to have previously trained on\n",
    "        continue\n",
    "        \n",
    "    zones = xbos_services_getter.get_zones(building_zone_names_stub,bldg)\n",
    "    action_df=pd.DataFrame()\n",
    "    \n",
    "    for zone in zones:\n",
    "        s = xbos_services_getter.get_indoor_actions_historic(indoor_data_historical_stub,bldg,zone,start,end,window,aggregate)\n",
    "        action_df = pd.concat([action_df, s], axis =1)\n",
    "\n",
    "    if bldg == \"csu-dominguez-hills\":\n",
    "        print(\"no meter or greenbutton data for csu-dominguez-hills\")\n",
    "        continue\n",
    "        \n",
    "    if bldg == \"jesse-turner-center\":\n",
    "        continue\n",
    "\n",
    "    electric_meter_data = xbos_services_getter.get_meter_data_historical(meter_data_historical_stub,bldg,start,end,electric_point_type,aggregate,window)\n",
    "    \n",
    "    data = pd.concat([action_df, electric_meter_data], axis =1)\n",
    "    data[\"X\"] = data.index\n",
    "    data.rename(columns={\"power\":\"y\"}, inplace =True)\n",
    "    \n",
    "    scalerY = MinMaxScaler(feature_range=(0, 1))\n",
    "    scalerX = MinMaxScaler(feature_range=(0, 1))\n",
    "    scalerS = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    data[\"is_weekday\"] = [is_weekday(x.weekday()) for x in data[\"X\"]]\n",
    "    data[\"is_workday\"] = [is_workday(x.hour) for x in data[\"X\"]]\n",
    "    data[\"is_spring\"]= [is_Spring(x.month) for x in data[\"X\"]]\n",
    "    data[\"is_summer\"]= [is_Summer(x.month) for x in data[\"X\"]]\n",
    "    data[\"is_autumn\"]= [is_Autumn(x.month) for x in data[\"X\"]]\n",
    "    data[\"is_winter\"]= [is_Winter(x.month) for x in data[\"X\"]]\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    if data.empty:\n",
    "        print(bldg+\" is empty\")\n",
    "        continue\n",
    "    \n",
    "    data[\"X\"] = scalerX.fit_transform(data[\"X\"].values.reshape(-1,1))\n",
    "    data[\"y\"] = scalerY.fit_transform(data[\"y\"].values.reshape(-1,1))\n",
    "\n",
    "    prediction_window=16\n",
    "    training_data=data[:-prediction_window]\n",
    "    test_data = data[-prediction_window:]\n",
    "\n",
    "    train_labels = training_data[\"y\"]\n",
    "    train_features = training_data.drop(\"y\", axis = 1)\n",
    "    test_labels = test_data[\"y\"]\n",
    "    test_features = test_data.drop(\"y\", axis = 1)\n",
    "    \n",
    "    params = best_params_dict[bldg]\n",
    "        \n",
    "    rf = RandomForestRegressor(max_depth = params[\"max_depth\"],\n",
    "                              min_impurity_decrease= params[\"min_impurity_decrease\"],\n",
    "                              min_samples_leaf = params[\"min_samples_leaf\"],\n",
    "                              min_samples_split = params[\"min_samples_split\"],\n",
    "                              n_estimators = params[\"n_estimators\"])\n",
    "    rf.fit(train_features, train_labels)\n",
    "    \n",
    "    # printing evaluation criteria\n",
    "   \n",
    "    evaluate_metrics[bldg] = evaluate(rf, train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avenal-veterans-hall': (0.061132208828488833, -inf),\n",
       " 'orinda-community-center': (0.106635924842908, -inf),\n",
       " 'local-butcher-shop': (0.11054764679974657, 56.943964948999394),\n",
       " 'avenal-public-works-yard': (0.0852879161829426, -inf),\n",
       " 'hayward-station-1': (0.05217284597382923, -inf),\n",
       " 'ciee': (0.070558040288807, -inf),\n",
       " 'berkeley-corporate-yard': (0.11146597285339532, 65.49463529776713),\n",
       " 'south-berkeley-senior-center': (0.14204553570422593, -3.873610772623053),\n",
       " 'avenal-movie-theatre': (0.06984034380386699, -inf),\n",
       " 'avenal-animal-shelter': (0.07083312798799471, -inf),\n",
       " 'north-berkeley-senior-center': (0.15847659029941874, -inf),\n",
       " 'word-of-faith-cc': (0.07548532712345768, -937.1049653232194),\n",
       " 'hayward-station-8': (0.03536464598881902, -inf)}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, train_features, train_labels):\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    e = []\n",
    "    a = []\n",
    "    for train_index, test_index in tscv.split(train_features):\n",
    "        rf.fit(train_features.iloc[train_index],train_labels.iloc[train_index])\n",
    "        predictions = model.predict(train_features.iloc[test_index])\n",
    "        errors = abs(predictions - train_labels.iloc[test_index])\n",
    "        mape = 100 * np.mean(errors / train_labels.iloc[test_index])\n",
    "        accuracy = 100 - mape\n",
    "        e.append(np.mean(errors))\n",
    "        a.append(accuracy)\n",
    "    return(np.mean(e), np.mean(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, test_features):\n",
    "    return(model.predict(test_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_Spring(month):\n",
    "    if month >3 and month<7:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "def is_Summer(month):\n",
    "    if month> 6 and month < 10:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0 \n",
    "\n",
    "def is_Autumn(month): \n",
    "    if month > 9:\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0 \n",
    "\n",
    "def is_Winter(month):\n",
    "    if month ==12 or month <3:\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def timeseries_to_supervised(data, lag=1, steps = 10, dropnan= True, prefix= \"\"):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    for i in range(lag, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [(prefix + 'var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    for i in range(0, steps):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [(prefix + 'var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [(prefix + 'var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    if dropnan: \n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "def is_weekday(day):\n",
    "    if day in range(0,5):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def is_workday(hour):\n",
    "    if hour in range(8,18):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def is_holiday(day):\n",
    "    holidays = pd.DatetimeIndex(['2016-11-11'])\n",
    "    for d in ('2016-11-11', '2016-11-24', '2016-11-25', '2016-12-23', '2016-12-26', '2016-12-30', '2017-01-16', '2017-02-20', \n",
    "              '2017-02-20', '2017-03-27', '2017-03-28', '2017-03-29', '2017-03-30', '2017-03-31', '2017-07-04', '2017-09-04',\n",
    "              '2017-11-10', '2017-11-23', '2017-11-24', '2017-12-22', '2017-12-25', '2017-12-29', '2018-01-01', '2018-01-15',\n",
    "              '2018-02-19', '2018-03-26', '2018-03-27', '2018-03-28', '2018-03-30', '2018-03-30', '2018-04-28', '2018-07-04',\n",
    "              '2018-09-03'\n",
    "             ):\n",
    "         holidays = holidays.append(pd.DatetimeIndex([d]))\n",
    "    \n",
    "    dateOnly = pd.DataFrame(pd.DatetimeIndex((data.index).date))\n",
    "\n",
    "    data['Holiday'] = pd.DatetimeIndex(dateOnly[0]).isin(holidays)\n",
    "    data['Holiday'] = data['Holiday'].replace({ True : 1, False : 0 })\n",
    "    \n",
    "\n",
    "def interpolate_uncontrolled(data):\n",
    "\n",
    "    data.ix[data[\"s0\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s1\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s2\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s3\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s4\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s5\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s6\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s7\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s8\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s9\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s10\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s11\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s12\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s13\"]>.2, \"y\"] = np.nan\n",
    "\n",
    "    data.ix[data[\"y\"].isna(), \"interpolated\"]=1\n",
    "    data.ix[data[\"interpolated\"].isna(), \"interpolated\"]=0\n",
    "\n",
    "    data[\"y\"].interpolate(method = \"piecewise_polynomial\", inplace=True)\n",
    "\n",
    "    data.drop([\"s0\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\", \"s7\", \"s8\", \"s9\", \"s10\", \"s11\", \"s12\", \"s13\"], axis = 1, inplace = True)\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def add_features(data):\n",
    "    data[\"is_weekday\"] = [is_weekday(x.weekday()) for x in data[\"X\"]]\n",
    "    data[\"is_workday\"] = [is_workday(x.hour) for x in data[\"X\"]]\n",
    "    data[\"is_spring\"]= [is_Spring(x.month) for x in data[\"X\"]]\n",
    "    data[\"is_summer\"]= [is_Summer(x.month) for x in data[\"X\"]]\n",
    "    data[\"is_autumn\"]= [is_Autumn(x.month) for x in data[\"X\"]]\n",
    "    data[\"is_winter\"]= [is_Winter(x.month) for x in data[\"X\"]]\n",
    "    return data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
