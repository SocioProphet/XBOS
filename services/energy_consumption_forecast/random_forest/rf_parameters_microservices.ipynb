{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "import xbos_services_getter\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "from scipy import spatial\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "start = datetime.datetime(year=2017, month=12, day=31, hour=16, minute=0).replace(tzinfo=pytz.utc)\n",
    "end = datetime.datetime(year = 2018, month = 5, day = 18, hour = 23, minute = 45).replace(tzinfo=pytz.utc)\n",
    "\n",
    "window = \"15m\"\n",
    "aggregate = 'MEAN'\n",
    "\n",
    "building_stub = xbos_services_getter.xbos_services_getter.get_building_zone_names_stub(\"ms.xbos.io:9001\", secure=True)\n",
    "\n",
    "\n",
    "buildings = xbos_services_getter.xbos_services_getter.get_buildings(building_stub)\n",
    "building_zone_names_stub = xbos_services_getter.get_building_zone_names_stub(\"ms.xbos.io:9001\")\n",
    "\n",
    "zones = xbos_services_getter.get_zones(building_stub, \"orinda-community-center\")\n",
    "\n",
    "temperature_band_stub = xbos_services_getter.get_temperature_band_stub(\"ms.xbos.io:9001\",secure=True)\n",
    "outdoor_temp_stub = xbos_services_getter.get_outdoor_temperature_historic_stub(\"ms.xbos.io:9001\",secure=True)\n",
    "outdoor_temp = xbos_services_getter.get_outdoor_temperature_historic(outdoor_temp_stub, \"orinda-community-center\", start, end,  window) \n",
    "# consumption_stub = xbos_services_getter.get_consumption_historic_stub()\n",
    "hvac_consumption_stub = xbos_services_getter.get_hvac_consumption_stub(\"ms.xbos.io:9001\",secure=True)\n",
    "hvac_consumption = xbos_services_getter.get_hvac_consumption(hvac_consumption_stub, \"orinda-community-center\", zone = 'hvac_zone_ac_7')\n",
    "indoor_data_historical_stub = xbos_services_getter.get_indoor_historic_stub(\"ms.xbos.io:9001\", secure=True)\n",
    "meter_data_historical_stub = xbos_services_getter.get_meter_data_historical_stub(\"ms.xbos.io:9001\", secure = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hvac_zone_ac_7',\n",
       " 'hvac_zone_rm7',\n",
       " 'hvac_zone_kinder_gym',\n",
       " 'hvac_zone_ac_6',\n",
       " 'hvac_zone_ac_3',\n",
       " 'hvac_zone_rm1',\n",
       " 'hvac_zone_ac_4',\n",
       " 'hvac_zone_ac_5',\n",
       " 'hvac_zone_rm6',\n",
       " 'hvac_zone_ac_1',\n",
       " 'hvac_zone_front_office',\n",
       " 'hvac_zone_ac_2',\n",
       " 'hvac_zone_rm2',\n",
       " 'hvac_zone_ac_8']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 0.075, 2: 3.3, 3: 0.01, 4: nan, 5: nan, 'UNIT': 'kWh'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvac_consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bldg = \"avenal-recreation-center\"\n",
    "\n",
    "electric_meter_data = xbos_services_getter.get_meter_data_historical(meter_data_historical_stub,bldg,start,end,electric_point_type,aggregate,window)\n",
    "\n",
    "zones = xbos_services_getter.get_zones(building_zone_names_stub,bldg)\n",
    "\n",
    "data = pd.concat([action_df, electric_meter_data], axis =1)\n",
    "data[\"X\"] = data.index\n",
    "\n",
    "data.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 15, 'min_impurity_decrease': 1e-08, 'min_samples_leaf': 3, 'min_samples_split': 15, 'n_estimators': 125}\n",
      "avenal-recreation-center is empty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 48.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'min_impurity_decrease': 1e-06, 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_impurity_decrease': 1e-08, 'min_samples_leaf': 7, 'min_samples_split': 15, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 18.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_impurity_decrease': 1e-07, 'min_samples_leaf': 20, 'min_samples_split': 20, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 29.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_impurity_decrease': 1e-06, 'min_samples_leaf': 7, 'min_samples_split': 25, 'n_estimators': 50}\n",
      "                           power\n",
      "datetime                        \n",
      "2017-12-31 16:00:00+00:00    NaN\n",
      "2017-12-31 16:15:00+00:00    NaN\n",
      "2017-12-31 16:30:00+00:00    NaN\n",
      "2017-12-31 16:45:00+00:00    NaN\n",
      "2017-12-31 17:00:00+00:00    NaN\n",
      "2017-12-31 17:15:00+00:00    NaN\n",
      "2017-12-31 17:30:00+00:00    NaN\n",
      "2017-12-31 17:45:00+00:00    NaN\n",
      "2017-12-31 18:00:00+00:00    NaN\n",
      "2017-12-31 18:15:00+00:00    NaN\n",
      "2017-12-31 18:30:00+00:00    NaN\n",
      "2017-12-31 18:45:00+00:00    NaN\n",
      "2017-12-31 19:00:00+00:00    NaN\n",
      "2017-12-31 19:15:00+00:00    NaN\n",
      "2017-12-31 19:30:00+00:00    NaN\n",
      "2017-12-31 19:45:00+00:00    NaN\n",
      "2017-12-31 20:00:00+00:00    NaN\n",
      "2017-12-31 20:15:00+00:00    NaN\n",
      "2017-12-31 20:30:00+00:00    NaN\n",
      "2017-12-31 20:45:00+00:00    NaN\n",
      "2017-12-31 21:00:00+00:00    NaN\n",
      "2017-12-31 21:15:00+00:00    NaN\n",
      "2017-12-31 21:30:00+00:00    NaN\n",
      "2017-12-31 21:45:00+00:00    NaN\n",
      "2017-12-31 22:00:00+00:00    NaN\n",
      "2017-12-31 22:15:00+00:00    NaN\n",
      "2017-12-31 22:30:00+00:00    NaN\n",
      "2017-12-31 22:45:00+00:00    NaN\n",
      "2017-12-31 23:00:00+00:00    NaN\n",
      "2017-12-31 23:15:00+00:00    NaN\n",
      "...                          ...\n",
      "2018-05-18 16:00:00+00:00    NaN\n",
      "2018-05-18 16:15:00+00:00    NaN\n",
      "2018-05-18 16:30:00+00:00    NaN\n",
      "2018-05-18 16:45:00+00:00    NaN\n",
      "2018-05-18 17:00:00+00:00    NaN\n",
      "2018-05-18 17:15:00+00:00    NaN\n",
      "2018-05-18 17:30:00+00:00    NaN\n",
      "2018-05-18 17:45:00+00:00    NaN\n",
      "2018-05-18 18:00:00+00:00    NaN\n",
      "2018-05-18 18:15:00+00:00    NaN\n",
      "2018-05-18 18:30:00+00:00    NaN\n",
      "2018-05-18 18:45:00+00:00    NaN\n",
      "2018-05-18 19:00:00+00:00    NaN\n",
      "2018-05-18 19:15:00+00:00    NaN\n",
      "2018-05-18 19:30:00+00:00    NaN\n",
      "2018-05-18 19:45:00+00:00    NaN\n",
      "2018-05-18 20:00:00+00:00    NaN\n",
      "2018-05-18 20:15:00+00:00    NaN\n",
      "2018-05-18 20:30:00+00:00    NaN\n",
      "2018-05-18 20:45:00+00:00    NaN\n",
      "2018-05-18 21:00:00+00:00    NaN\n",
      "2018-05-18 21:15:00+00:00    NaN\n",
      "2018-05-18 21:30:00+00:00    NaN\n",
      "2018-05-18 21:45:00+00:00    NaN\n",
      "2018-05-18 22:00:00+00:00    NaN\n",
      "2018-05-18 22:15:00+00:00    NaN\n",
      "2018-05-18 22:30:00+00:00    NaN\n",
      "2018-05-18 22:45:00+00:00    NaN\n",
      "2018-05-18 23:00:00+00:00    NaN\n",
      "2018-05-18 23:15:00+00:00    NaN\n",
      "\n",
      "[13278 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 22.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_impurity_decrease': 1e-06, 'min_samples_leaf': 15, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "no meter or greenbutton data for csu-dominguez-hills\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed:  9.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_impurity_decrease': 1e-08, 'min_samples_leaf': 20, 'min_samples_split': 20, 'n_estimators': 125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 1146.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_impurity_decrease': 1e-07, 'min_samples_leaf': 15, 'min_samples_split': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 24.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_impurity_decrease': 1e-08, 'min_samples_leaf': 7, 'min_samples_split': 25, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_impurity_decrease': 1e-07, 'min_samples_leaf': 3, 'min_samples_split': 20, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 13.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_impurity_decrease': 1e-06, 'min_samples_leaf': 20, 'min_samples_split': 10, 'n_estimators': 75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 13.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_impurity_decrease': 1e-08, 'min_samples_leaf': 3, 'min_samples_split': 25, 'n_estimators': 75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype datetime64[ns] was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n",
      "{'max_depth': 3, 'min_impurity_decrease': 1e-08, 'min_samples_leaf': 3, 'min_samples_split': 25, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed:  8.6min finished\n"
     ]
    }
   ],
   "source": [
    "electric_point_type = 'Building_Electric_Meter'\n",
    "\n",
    "best_params_dict = {}\n",
    "\n",
    "for bldg in buildings:\n",
    "    zones = xbos_services_getter.get_zones(building_zone_names_stub,bldg)\n",
    "    action_df=pd.DataFrame()\n",
    "    for zone in zones:\n",
    "        s = xbos_services_getter.get_indoor_actions_historic(indoor_data_historical_stub,bldg,zone,start,end,window,aggregate)\n",
    "        action_df = pd.concat([action_df, s], axis =1)\n",
    "\n",
    "    if bldg == \"csu-dominguez-hills\":\n",
    "        print(\"no meter or greenbutton data for csu-dominguez-hills\")\n",
    "        continue\n",
    "        \n",
    "# NO GREENBUTTON DATA FOR jesse-turner-center\n",
    "    if bldg == \"jesse-turner-center\":\n",
    "        electric_meter_data = xbos_services_getter.get_meter_data_historical(meter_data_historical_stub,bldg,start,end,electric_point_type,aggregate,window)\n",
    "        print(electric_meter_data)\n",
    "        continue\n",
    "\n",
    "    electric_meter_data = xbos_services_getter.get_meter_data_historical(meter_data_historical_stub,bldg,start,end,electric_point_type,aggregate,window)\n",
    "    \n",
    "    data = pd.concat([action_df, electric_meter_data], axis =1)\n",
    "    data[\"X\"] = data.index\n",
    "    data.rename(columns={\"power\":\"y\"}, inplace =True)\n",
    "    \n",
    "    scalerY = MinMaxScaler(feature_range=(0, 1))\n",
    "    scalerX = MinMaxScaler(feature_range=(0, 1))\n",
    "    scalerS = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    data[\"is_weekday\"] = [is_weekday(x.weekday()) for x in data[\"X\"]]\n",
    "    data[\"is_workday\"] = [is_workday(x.hour) for x in data[\"X\"]]\n",
    "    data[\"is_spring\"]= [is_Spring(x.month) for x in data[\"X\"]]\n",
    "    data[\"is_summer\"]= [is_Summer(x.month) for x in data[\"X\"]]\n",
    "    data[\"is_autumn\"]= [is_Autumn(x.month) for x in data[\"X\"]]\n",
    "    data[\"is_winter\"]= [is_Winter(x.month) for x in data[\"X\"]]\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    if data.empty:\n",
    "        print(bldg+\" is empty\")\n",
    "        continue\n",
    "    \n",
    "    data[\"X\"] = scalerX.fit_transform(data[\"X\"].values.reshape(-1,1))\n",
    "    data[\"y\"] = scalerY.fit_transform(data[\"y\"].values.reshape(-1,1))\n",
    "\n",
    "    prediction_window=16\n",
    "    training_data=data[:-prediction_window]\n",
    "    test_data = data[-prediction_window:]\n",
    "\n",
    "    train_labels = training_data[\"y\"]\n",
    "    train_features = training_data.drop(\"y\", axis = 1)\n",
    "    test_labels = test_data[\"y\"]\n",
    "    test_features = test_data.drop(\"y\", axis = 1)\n",
    "    \n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    parameters = {\n",
    "        'n_estimators':[50, 75,125],\n",
    "        'max_depth': [3, 5, 15,20],\n",
    "        \"min_samples_split\":[5,10, 15, 20, 25],\n",
    "        'min_samples_leaf': [3, 7, 12, 15, 20],\n",
    "        \"min_impurity_decrease\": [1e-7, 1e-6, 1e-8]\n",
    "    }\n",
    "\n",
    "    clf = GridSearchCV(rf, parameters, cv=3, verbose = 1)\n",
    "    clf.fit(train_features, train_labels)\n",
    "    \n",
    "    print(clf.best_params_)\n",
    "    best_params_dict[bldg] = clf.best_params_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avenal-veterans-hall': {'max_depth': 15,\n",
       "  'min_impurity_decrease': 1e-07,\n",
       "  'min_samples_leaf': 3,\n",
       "  'min_samples_split': 15,\n",
       "  'n_estimators': 75},\n",
       " 'orinda-community-center': {'max_depth': 10,\n",
       "  'min_impurity_decrease': 1e-07,\n",
       "  'min_samples_leaf': 3,\n",
       "  'min_samples_split': 10,\n",
       "  'n_estimators': 125},\n",
       " 'local-butcher-shop': {'max_depth': 5,\n",
       "  'min_impurity_decrease': 1e-07,\n",
       "  'min_samples_leaf': 12,\n",
       "  'min_samples_split': 20,\n",
       "  'n_estimators': 75},\n",
       " 'avenal-public-works-yard': {'max_depth': 5,\n",
       "  'min_impurity_decrease': 1e-06,\n",
       "  'min_samples_leaf': 12,\n",
       "  'min_samples_split': 10,\n",
       "  'n_estimators': 75},\n",
       " 'hayward-station-1': {'max_depth': 5,\n",
       "  'min_impurity_decrease': 5e-07,\n",
       "  'min_samples_leaf': 7,\n",
       "  'min_samples_split': 15,\n",
       "  'n_estimators': 75},\n",
       " 'ciee': {'max_depth': 5,\n",
       "  'min_impurity_decrease': 1e-07,\n",
       "  'min_samples_leaf': 7,\n",
       "  'min_samples_split': 15,\n",
       "  'n_estimators': 75},\n",
       " 'berkeley-corporate-yard': {'max_depth': 5,\n",
       "  'min_impurity_decrease': 1e-07,\n",
       "  'min_samples_leaf': 3,\n",
       "  'min_samples_split': 10,\n",
       "  'n_estimators': 75},\n",
       " 'south-berkeley-senior-center': {'max_depth': 5,\n",
       "  'min_impurity_decrease': 1e-07,\n",
       "  'min_samples_leaf': 3,\n",
       "  'min_samples_split': 15,\n",
       "  'n_estimators': 75},\n",
       " 'avenal-movie-theatre': {'max_depth': 5,\n",
       "  'min_impurity_decrease': 1e-07,\n",
       "  'min_samples_leaf': 7,\n",
       "  'min_samples_split': 15,\n",
       "  'n_estimators': 100},\n",
       " 'avenal-animal-shelter': {'max_depth': 10,\n",
       "  'min_impurity_decrease': 1e-07,\n",
       "  'min_samples_leaf': 12,\n",
       "  'min_samples_split': 10,\n",
       "  'n_estimators': 75},\n",
       " 'north-berkeley-senior-center': {'max_depth': 5,\n",
       "  'min_impurity_decrease': 1e-06,\n",
       "  'min_samples_leaf': 12,\n",
       "  'min_samples_split': 20,\n",
       "  'n_estimators': 100},\n",
       " 'word-of-faith-cc': {'max_depth': 5,\n",
       "  'min_impurity_decrease': 1e-06,\n",
       "  'min_samples_leaf': 3,\n",
       "  'min_samples_split': 20,\n",
       "  'n_estimators': 125},\n",
       " 'hayward-station-8': {'max_depth': 15,\n",
       "  'min_impurity_decrease': 5e-07,\n",
       "  'min_samples_leaf': 12,\n",
       "  'min_samples_split': 15,\n",
       "  'n_estimators': 125}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_Spring(month):\n",
    "    if month >3 and month<7:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "def is_Summer(month):\n",
    "    if month> 6 and month < 10:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0 \n",
    "\n",
    "def is_Autumn(month): \n",
    "    if month > 9:\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0 \n",
    "\n",
    "def is_Winter(month):\n",
    "    if month ==12 or month <3:\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def timeseries_to_supervised(data, lag=1, steps = 10, dropnan= True, prefix= \"\"):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    for i in range(lag, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [(prefix + 'var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    for i in range(0, steps):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [(prefix + 'var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [(prefix + 'var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    if dropnan: \n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "def is_weekday(day):\n",
    "    if day in range(0,5):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def is_workday(hour):\n",
    "    if hour in range(8,18):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def is_holiday(day):\n",
    "    holidays = pd.DatetimeIndex(['2016-11-11'])\n",
    "    for d in ('2016-11-11', '2016-11-24', '2016-11-25', '2016-12-23', '2016-12-26', '2016-12-30', '2017-01-16', '2017-02-20', \n",
    "              '2017-02-20', '2017-03-27', '2017-03-28', '2017-03-29', '2017-03-30', '2017-03-31', '2017-07-04', '2017-09-04',\n",
    "              '2017-11-10', '2017-11-23', '2017-11-24', '2017-12-22', '2017-12-25', '2017-12-29', '2018-01-01', '2018-01-15',\n",
    "              '2018-02-19', '2018-03-26', '2018-03-27', '2018-03-28', '2018-03-30', '2018-03-30', '2018-04-28', '2018-07-04',\n",
    "              '2018-09-03'\n",
    "             ):\n",
    "         holidays = holidays.append(pd.DatetimeIndex([d]))\n",
    "    \n",
    "    dateOnly = pd.DataFrame(pd.DatetimeIndex((data.index).date))\n",
    "\n",
    "    data['Holiday'] = pd.DatetimeIndex(dateOnly[0]).isin(holidays)\n",
    "    data['Holiday'] = data['Holiday'].replace({ True : 1, False : 0 })\n",
    "    \n",
    "\n",
    "def interpolate_uncontrolled(data):\n",
    "\n",
    "    data.ix[data[\"s0\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s1\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s2\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s3\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s4\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s5\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s6\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s7\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s8\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s9\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s10\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s11\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s12\"]>.2, \"y\"] = np.nan\n",
    "    data.ix[data[\"s13\"]>.2, \"y\"] = np.nan\n",
    "\n",
    "    data.ix[data[\"y\"].isna(), \"interpolated\"]=1\n",
    "    data.ix[data[\"interpolated\"].isna(), \"interpolated\"]=0\n",
    "\n",
    "    data[\"y\"].interpolate(method = \"piecewise_polynomial\", inplace=True)\n",
    "\n",
    "    data.drop([\"s0\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\", \"s7\", \"s8\", \"s9\", \"s10\", \"s11\", \"s12\", \"s13\"], axis = 1, inplace = True)\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def add_features(data):\n",
    "    data[\"is_weekday\"] = [is_weekday(x.weekday()) for x in data[\"X\"]]\n",
    "    data[\"is_workday\"] = [is_workday(x.hour) for x in data[\"X\"]]\n",
    "    data[\"is_spring\"]= [is_Spring(x.month) for x in data[\"X\"]]\n",
    "    data[\"is_summer\"]= [is_Summer(x.month) for x in data[\"X\"]]\n",
    "    data[\"is_autumn\"]= [is_Autumn(x.month) for x in data[\"X\"]]\n",
    "    data[\"is_winter\"]= [is_Winter(x.month) for x in data[\"X\"]]\n",
    "    return data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
